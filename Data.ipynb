{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "We've already provided the code needed to load the data, perform iterative parsing and write the\n",
    "output to csv files. Your task is to complete the shape_element function that will transform each\n",
    "element into the correct format. To make this process easier we've already defined a schema (see\n",
    "the schema.py file in the last code tab) for the .csv files and the eventual tables. Using the \n",
    "cerberus library we can validate the output against this schema to ensure it is correct.\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": .., \"node_tags\": ...}\n",
    "\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "\n",
    "The final return value for a \"node\" element should look something like:\n",
    "\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "-  user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "\n",
    "The final return value for a \"way\" element should look something like:\n",
    "\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "import cerberus\n",
    "\n",
    "import schema\n",
    "\n",
    "#OSM_PATH = \"sample10.osm\"\n",
    "OSM_PATH = \"san-jose_california.osm\"\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "POSTCODE = re.compile(r'[9][0-9]{4}$')\n",
    "PHONENUM =re.compile(r'[4,5,6,8][0-9]{2}-[0-9]{3}-[0-9]{4}$')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "mapping_addr = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\" : \"Road\",\n",
    "            \"Blvd\" : \"Boulevard\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            u'Monta√±a':\"Montana\",\n",
    "            \"Ct\" : \"Court\",\n",
    "            \"Ln\" : \"Lane\"\n",
    "            }\n",
    "\n",
    "mapping_city = { \"SUnnyvale\" : \"Sunnyvale\",\n",
    "                 \"Los Gato\" : \"Los Gatos\",\n",
    "                 u'San Jos\\xe9' : \"San Jose\",\n",
    "                 \"cupertino\" : \"Cupertino\",\n",
    "                 \"sunnyvale\": \"Sunnyvale\",\n",
    "                 \"san Jose\": \"San Jose\",\n",
    "                 \"san jose\": \"San Jose\",\n",
    "                 \"Los Gatos, CA\": \"Los Gatos\",\n",
    "                 \"Mt Hamilton\": \"Mount Hamilton\"\n",
    "                 }\n",
    "direction_addr = {'N':'North','S':'South','E':'East','W':'West','N.':'North','S.':'South','E.':'East','W.':'West'}\n",
    "expand_addr = {\"Mt Hamilton Rd\": \"Mount Hamilton Road\"}\n",
    "street_num ={'1st':'First','2nd':'Second','3rd':'Third'}\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#\n",
    "#     These are the four cleaning functions\n",
    "# update_addr_name(),update_city_name(),update_postcode(),update_phone()\n",
    "# print name,' ----> ',newname is for debugging\n",
    "#\n",
    "############################################################################\n",
    "\n",
    "# update the names of streets using 'mapping_adr','direction_addr',\n",
    "# 'expand_addr' and 'street_num' dictionaries\n",
    "\n",
    "def update_addr_name(name, mapping):\n",
    "    newname = ''\n",
    "    #replace N with North,S with South etc.\n",
    "    if name.split()[0] in direction_addr:\n",
    "        for key,val in direction.iteritems():\n",
    "            name = name.replace(key,val)\n",
    "    if name in expand_addr:\n",
    "        newname = expand_addr[name]\n",
    "#        print name,' ----> ',newname\n",
    "        return (newname)\n",
    "    #replace 1st with 'First' etc.\n",
    "    name_list = name.split()\n",
    "    for items in name_list:\n",
    "        if items in street_num:\n",
    "            for key,val in street_num.iteritems():\n",
    "                name = name.replace(key,val)\n",
    "        \n",
    "    last_word = name.split()[-1]\n",
    "    if last_word in mapping_addr:\n",
    "        #get the words except the last one\n",
    "        for n in range(len(name.split())-1):\n",
    "            newname += name.split()[n]\n",
    "            newname +=' '\n",
    "        newname += mapping_addr[last_word]\n",
    "#        print name,' ----> ',newname\n",
    "        return newname\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "\n",
    "#update the city names using the 'mapping_city' and 'expand_city' \n",
    "#dictionaries\n",
    "\n",
    "def update_city_name(name,mapping):\n",
    "    new_name=''\n",
    "    if name in mapping_city: \n",
    "        new_name = mapping_city[name]\n",
    "#        print name,' ----> ',repr(new_name)\n",
    "        return repr(new_name)\n",
    "    else:\n",
    "        return repr(name)\n",
    "\n",
    "#update the 9-digit postcodes to 5-digit\n",
    "\n",
    "def update_postcode(postcode):\n",
    "    if POSTCODE.match(postcode):\n",
    "        return postcode\n",
    "    elif postcode.split()[0] == 'CA':\n",
    "#        print postcode,' ---->',postcode.split()[1]\n",
    "        return (postcode.split()[1])\n",
    "    else:\n",
    "#        print postcode,' ----> ',postcode.split('-')[0]\n",
    "        return (postcode.split('-')[0])\n",
    "    \n",
    "\n",
    "#update the phone number to the standard format (xxx) xxx-xxxx \n",
    "\n",
    "def update_phone(phonenum):\n",
    "    if PHONENUM.match(phonenum):\n",
    "        return phonenum\n",
    "    else:\n",
    "        new_num=''\n",
    "        count = 0\n",
    "        for i in range(len(phonenum)):\n",
    "        #get the first number\n",
    "            if (phonenum[i] in ['4','5','6','8']) and count == 0:\n",
    "                new_num += \"(\"\n",
    "                new_num += phonenum[i]\n",
    "                count +=1\n",
    "            elif (count > 0) and (count <= 12):\n",
    "                if phonenum[i].isalnum():\n",
    "                    new_num += phonenum[i]\n",
    "                    count +=1\n",
    "                    if count == 3:\n",
    "                        new_num+= \") \"\n",
    "                    if count == 6:\n",
    "                        if new_num[6].isdigit():\n",
    "                            new_num += \"-\"\n",
    "    if len(new_num) > 9 and len(new_num) <=14:\n",
    "#        print phonenum,' ----> ',new_num\n",
    "        return new_num    \n",
    "    else:\n",
    "#        print 'Invalid phone number: ',phonenum\n",
    "        return ('Invalid phone number')\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        #get the node attributes\n",
    "        for fields in node_attr_fields:\n",
    "            node_attribs[fields] = element.attrib[fields]\n",
    "        # get the tag attributes\n",
    "        for t in element.iter('tag'):\n",
    "            t_dict = {}\n",
    "            t_dict['id'] = element.attrib['id']\n",
    "            #if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "            if PROBLEMCHARS.match(t.attrib['k']):\n",
    "                continue;\n",
    "            #if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "            #and characters after the \":\" should be set as the tag key\n",
    "            #if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "            # the tag key. \n",
    "            if not(':' in t.attrib['k']):\n",
    "                t_dict['key'] = t.attrib['k']\n",
    "                t_dict['type'] = 'regular';\n",
    "            else:\n",
    "                key_str = t.attrib['k']\n",
    "                val = key_str.split(':')\n",
    "                value=''\n",
    "                for items in val[1:]:\n",
    "                    value +=items\n",
    "                t_dict['key'] = value\n",
    "                t_dict['type'] = val[0]\n",
    "            # fix the street name,city name,postcode,phone\n",
    "            if t.attrib['k'] == 'addr:street':\n",
    "                t_dict['value'] = update_addr_name(t.attrib['v'],mapping_addr)\n",
    "            elif t.attrib['k'] == 'addr:city':\n",
    "                t_dict['value'] = update_city_name(t.attrib['v'],mapping_city)\n",
    "            elif t.attrib['k'] == 'addr:postcode':\n",
    "                t_dict['value'] = update_postcode(t.attrib['v'])\n",
    "            elif t.attrib['k'] == 'phone':\n",
    "                t_dict['value'] = update_phone(t.attrib['v'])\n",
    "            else:\n",
    "                t_dict['value'] = t.attrib['v']\n",
    "            tags.append(t_dict)\n",
    "    elif element.tag == 'way':\n",
    "        for fields in way_attr_fields:\n",
    "            way_attribs[fields] = element.attrib[fields]\n",
    "        for t in element.iter('tag'):\n",
    "            t_dict = {}\n",
    "            t_dict['id'] = element.attrib['id']\n",
    "            if PROBLEMCHARS.match(t.attrib['k']):\n",
    "                continue;\n",
    "            if not(':' in t.attrib['k']):\n",
    "                t_dict['key'] = t.attrib['k']\n",
    "                t_dict['type'] = 'regular';\n",
    "            else:\n",
    "                key_str = t.attrib['k']\n",
    "                val = key_str.split(':',1)\n",
    "                t_dict['key'] = val[1]\n",
    "                t_dict['type'] = val[0]\n",
    "            # fix the street name,city name,postcode,phone\n",
    "            if t.attrib['k'] == 'addr:street':\n",
    "                t_dict['value'] = update_addr_name(t.attrib['v'],mapping_addr)\n",
    "            elif t.attrib['k'] == 'addr:city':\n",
    "                t_dict['value'] = update_city_name(t.attrib['v'],mapping_city)\n",
    "            elif t.attrib['k'] == 'addr:postcode':\n",
    "                t_dict['value'] = update_postcode(t.attrib['v'])\n",
    "            elif t.attrib['k'] == 'phone':\n",
    "                t_dict['value'] = update_phone(t.attrib['v'])\n",
    "            else:\n",
    "                t_dict['value'] = t.attrib['v']\n",
    "            tags.append(t_dict)\n",
    "        pos = 0\n",
    "        for w in element.iter('nd'):\n",
    "            wd = {}\n",
    "            wd['id'] = element.attrib['id']\n",
    "            wd['node_id'] = w.attrib['ref']\n",
    "            wd['position'] = pos \n",
    "            way_nodes.append(wd)\n",
    "            pos +=1\n",
    "\n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sqlite> select count(value) from nodes_tags where key == 'postcode' and value != \"\";\n",
    "2901\n",
    "sqlite> select count(*) from nodes_tags where key == 'postcode';\n",
    "2902\n",
    "select count(DISTINCT value) from nodes_tags where key == 'postcode';\n",
    "47\n",
    "sqlite> select count(DISTINCT value) from nodes_tags where key == 'city';\n",
    "15\n",
    "sqlite> select DISTINCT value from nodes_tags where key == 'city';\n",
    "\"San Jose\"\n",
    "\"'Sunnyvale'\"\n",
    "\"'Santa Clara'\"\n",
    "\"'San Jose'\"\n",
    "\"'Morgan Hill'\"\n",
    "\"'Campbell'\"\n",
    "\"'Los Gatos'\"\n",
    "\"'Saratoga'\"\n",
    "\"'Cupertino'\"\n",
    "\"'Mt Hamilton'\"\n",
    "\"'Milpitas'\"\n",
    "\"'Felton'\"\n",
    "\"'Los Gatos, CA'\"\n",
    "\"'Coyote'\"\n",
    "\"'Fremont'\"\n",
    "\n",
    "sqlite> select count(DISTINCT value) from nodes_tags where key == 'street';\n",
    "650\n",
    "\n",
    "sqlite> select count(*) as cnt,nodes.user from nodes\n",
    "   ...> group by nodes.user\n",
    "   ...> order by cnt desc\n",
    "   ...> limit 12;\n",
    "251976,nmixter\n",
    "142669,mk408\n",
    "70672,\"Bike Mapper\"\n",
    "68445,samely\n",
    "66552,dannykath\n",
    "64095,RichRico\n",
    "52359,karitotp\n",
    "31133,n76\n",
    "30166,MustangBuyer\n",
    "29777,\"Minh Nguyen\"\n",
    "28140,matthieun\n",
    "28110,doug_sfba\n",
    "\n",
    "\n",
    "sqlite> select count(*) as cnt,nodes.user from nodes\n",
    "   ...> group by nodes.user\n",
    "   ...> order by cnt\n",
    "   ...> limit 20;\n",
    "1,Aleks-Berlin\n",
    "1,Allison13\n",
    "1,\"Amir Hameed\"\n",
    "1,\"Amir M\"\n",
    "1,AmitNarayanGupta\n",
    "1,\"Amogh Rane\"\n",
    "1,Anatolikus\n",
    "1,AndiG88\n",
    "1,Andre68\n",
    "1,AndrewO\n",
    "1,Andy88\n",
    "1,AnhTran\n",
    "1,B777600\n",
    "1,BAdlesh\n",
    "1,BFX\n",
    "1,BenCook\n",
    "1,\"Bens Iliadd\"\n",
    "1,Blaine\n",
    "1,\"Blank Reg\"\n",
    "1,Bootprint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
